ModelArguments:                                                                                                                                                           
  model_name_or_path: lmsys/vicuna-13b-v1.5                                                                                                                               
  version: plain                                                                                                                                                          
  freeze_backbone: False                                                                                                                                                  
  tune_mm_mlp_adapter: True                                                                                                                                               
  vision_tower: openai/clip-vit-large-patch14-336                                                                                                                         
  mm_vision_select_layer: -2                                                                                                                                              
  pretrain_mm_mlp_adapter: None                                                                                                                                           
  mm_projector_type: mlp2x_gelu                                                                                                                                           
  mm_use_im_start_end: False                                                                                                                                              
  mm_use_im_patch_token: False                                                                                                                                            
  mm_patch_merge_type: flat                                                                                                                                               
  mm_vision_select_feature: patch  


DataArguments:                                                                                                                                                            
  data_path: ./playground/data/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json                                                                                                 
  lazy_preprocess: True                                                                                                                                                   
  is_multimodal: False
  image_folder: ./playground/data/LLaVA-Pretrain/images
  image_aspect_ratio: square



TrainingArguments:
  cache_dir: None
  optim: OptimizerNames.ADAMW_TORCH
  remove_unused_columns: False
  freeze_mm_mlp_adapter: False
  mpt_attn_impl: triton
  model_max_length: 2048
  double_quant: True
  quant_type: nf4
  bits: 16
  lora_enable: False
  lora_r: 64
  lora_alpha: 16
  lora_dropout: 0.05
  lora_weight_path: 
  lora_bias: none
  mm_projector_lr: None
  group_by_modality_length: False